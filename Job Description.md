Build GPU accelerated scalable LLM driven Retrieval Augmented Generation(RAG) workflow and build a scalable microservice based architecture deployable on multi-node, multi-cloud environment

Build domain specific agents and workflows and build a framework which can support multi-turn, multi-modal, multi-user conversations with a LLM driven agents.

Develop knowledge discovery, and reasoning capabilities including but not limited to disambiguation, clarification, and anticipation for dialogue systems

Evaluate and benchmark end to end RAG and conversational AI agent pipelines for accuracy as well as system performance

Analyze RAG and conversational AI agent end to end accuracy and limitations and recommend the next course of action & Improvements.

Characterize performance and quality metrics across platforms for various AI and system components

Collaborate with various teams on new product features and improvements of existing products. Customize and integrate the 
conversational AI framework with other NVIDIA products

Participate in developing and reviewing code, design documents, use case reviews, and test plan reviews and help innovate, identify problems, recommend solutions and perform triage in a collaborative team environment.

Do you have experience in Fine Tuning LLM's like GPT, Llama, Falcon, Palm

Do you have experience working with Vector Databases like Pinecone, Weaviate, Chroma DB , Faiss ?
